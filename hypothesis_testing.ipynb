{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignment 2: Hypothesis Testing\n",
    "\n",
    "Hypothesis: Model trained on old data will do less well than more recent data.\n",
    "Method: Taking responses from different years (e.g. 2018 vs 2020) to 4 intention questions, we train a logistic regression model and compare model performance on a held-out test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# HERE ARE ALL THE FUNCTIONS TO PREPROCESS DATA, TRAIN MODEL, GENERATE PREDICTIONS\n",
    "# Note: since we use the PreFer training data, we cannot upload to github. If you wish to test the code to make sure it runs, you can use the fake data provided.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import joblib\n",
    "import random\n",
    "\n",
    "\n",
    "def clean_df(df, background_df=None):\n",
    "    \"\"\"\n",
    "    Preprocess the input dataframe to feed the model.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe containing the raw data (e.g., from PreFer_train_data.csv or PreFer_fake_data.csv).\n",
    "    background (pd.DataFrame): Optional input dataframe containing background data (e.g., from PreFer_train_background_data.csv or PreFer_fake_background_data.csv).\n",
    "\n",
    "    Returns:\n",
    "    dfs (pd.DataFrame): The cleaned dataframes with only the necessary columns and processed variables per year.\n",
    "    \"\"\"\n",
    "\n",
    "    # Grab variables depending on the year\n",
    "    keepcols_2015 = [\n",
    "\n",
    "    ]\n",
    "\n",
    "    keepcols_2016 = [\n",
    "\n",
    "    ]\n",
    "\n",
    "    keepcols_2017 = [\n",
    "\n",
    "    ]\n",
    "\n",
    "    keepcols_2018 = [\n",
    "\n",
    "    ]\n",
    "\n",
    "    keepcols_2019 = [\n",
    "\n",
    "    ]\n",
    "    \n",
    "    keepcols_2020 = [\n",
    "        \"nomem_encr\",  # ID variable required for predictions,\n",
    "        \"birthyear_bg\",\n",
    "        \"age_bg\",\n",
    "        \"cf20m130\", # Within how many years do you hope to have your first/next child?\n",
    "        \"cf20m128\", # Do you think you will have children in the future?\n",
    "        \"cf20m129\", # How many children do you think you'll have?\n",
    "        \"cf20m031\" # What year did you marry?\n",
    "\n",
    "    ] \n",
    "\n",
    "    # Keeping data with variables selected for each year\n",
    "    dfs = {year: df[keepcols] for year, keepcols in zip(range(2015, 2021), [keepcols_2015, keepcols_2016, keepcols_2017, keepcols_2018, keepcols_2019, keepcols_2020])}\n",
    "\n",
    "    # Calculate the median for each column\n",
    "    medians = df.median()\n",
    "\n",
    "    # Fill missing values with the median of each column for each year\n",
    "    dfs = {year: df.fillna(medians) for year, df in dfs.items()}\n",
    "\n",
    "    return dfs\n",
    "    \n",
    "\n",
    "\n",
    "\n",
    "def train_save_model(cleaned_df, outcome_df):\n",
    "    \"\"\"\n",
    "    Trains a model using the cleaned dataframe and saves the model to a file.\n",
    "\n",
    "    Parameters:\n",
    "    cleaned_df (pd.DataFrame): The cleaned data from clean_df function to be used for training the model.\n",
    "    outcome_df (pd.DataFrame): The data with the outcome variable (e.g., from PreFer_train_outcome.csv or PreFer_fake_outcome.csv).\n",
    "    \"\"\"\n",
    "    \n",
    "    ## This script contains a bare minimum working example\n",
    "    \n",
    "    # Combine cleaned_df and outcome_df\n",
    "    model_df = pd.merge(cleaned_df, outcome_df, on=\"nomem_encr\")\n",
    "\n",
    "    # Filter cases for whom the outcome is not available\n",
    "    model_df = model_df[~model_df['new_child'].isna()]  \n",
    "    X = model_df.drop(['new_child', 'nomem_encr'], axis=1)\n",
    "    y = model_df['new_child']\n",
    "\n",
    "    # Define the model\n",
    "    model = LogisticRegression(verbose=10)\n",
    "\n",
    "    # Fit the model\n",
    "    model.fit(X,y)\n",
    "\n",
    "    # Save the model\n",
    "    joblib.dump(model, \"model.joblib\")\n",
    "\n",
    "    # Print progress\n",
    "    print(\"Model saved.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_outcomes(df, background_df=None, model_path=\"model.joblib\"):\n",
    "    \"\"\"Generate predictions using the saved model and the input dataframe.\n",
    "\n",
    "    The predict_outcomes function accepts a Pandas DataFrame as an argument\n",
    "    and returns a new DataFrame with two columns: nomem_encr and\n",
    "    prediction. The nomem_encr column in the new DataFrame replicates the\n",
    "    corresponding column from the input DataFrame. The prediction\n",
    "    column contains predictions for each corresponding nomem_encr. Each\n",
    "    prediction is represented as a binary value: '0' indicates that the\n",
    "    individual did not have a child during 2021-2023, while '1' implies that\n",
    "    they did.\n",
    "\n",
    "    Parameters:\n",
    "    df (pd.DataFrame): The input dataframe for which predictions are to be made.\n",
    "    background_df (pd.DataFrame): The background dataframe for which predictions are to be made.\n",
    "    model_path (str): The path to the saved model file (which is the output of training.py).\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: A dataframe containing the identifiers and their corresponding predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    ## This script contains a bare minimum working example\n",
    "    if \"nomem_encr\" not in df.columns:\n",
    "        print(\"The identifier variable 'nomem_encr' should be in the dataset\")\n",
    "\n",
    "    # Load the model\n",
    "    model = joblib.load(model_path)\n",
    "\n",
    "    # Preprocess the fake / holdout data\n",
    "    df = clean_df(df, background_df)\n",
    "\n",
    "    # Exclude the variable nomem_encr if this variable is NOT in your model\n",
    "    vars_without_id = df.columns[df.columns != 'nomem_encr']\n",
    "\n",
    "    # Generate predictions from model, should be 0 (no child) or 1 (had child)\n",
    "    predictions = model.predict(df[vars_without_id])\n",
    "\n",
    "    # Output file should be DataFrame with two columns, nomem_encr and predictions\n",
    "    df_predict = pd.DataFrame(\n",
    "        {\"nomem_encr\": df[\"nomem_encr\"], \"prediction\": predictions}\n",
    "    )\n",
    "\n",
    "    # Return only dataset with predictions and identifier\n",
    "    return df_predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def score(prediction_path, ground_truth_path):\n",
    "    \"\"\"Score (evaluate) the predictions and write the metrics.\n",
    "\n",
    "    This function takes the path to a CSV file containing predicted outcomes and the\n",
    "    path to a CSV file containing the ground truth outcomes. It calculates the overall\n",
    "    prediction accuracy, and precision, recall, and F1 score for having a child\n",
    "    and writes these scores to a new output CSV file.\n",
    "\n",
    "    This function should not be modified.\n",
    "    \"\"\"\n",
    "\n",
    "    # Load predictions and ground truth into dataframes\n",
    "    predictions_df = pd.read_csv(prediction_path)\n",
    "    ground_truth_df = pd.read_csv(ground_truth_path)\n",
    "\n",
    "    # Merge predictions and ground truth on the 'id' column\n",
    "    merged_df = pd.merge(predictions_df, ground_truth_df, on=\"nomem_encr\", how=\"right\")\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = len(merged_df[merged_df[\"prediction\"] == merged_df[\"new_child\"]]) / len(\n",
    "        merged_df\n",
    "    )\n",
    "\n",
    "    # Calculate true positives, false positives, and false negatives\n",
    "    true_positives = len(\n",
    "        merged_df[(merged_df[\"prediction\"] == 1) & (merged_df[\"new_child\"] == 1)]\n",
    "    )\n",
    "    false_positives = len(\n",
    "        merged_df[(merged_df[\"prediction\"] == 1) & (merged_df[\"new_child\"] == 0)]\n",
    "    )\n",
    "    false_negatives = len(\n",
    "        merged_df[(merged_df[\"prediction\"] == 0) & (merged_df[\"new_child\"] == 1)]\n",
    "    )\n",
    "\n",
    "    # Calculate precision, recall, and F1 score\n",
    "    try:\n",
    "        precision = true_positives / (true_positives + false_positives)\n",
    "    except ZeroDivisionError:\n",
    "        precision = 0\n",
    "    try:\n",
    "        recall = true_positives / (true_positives + false_negatives)\n",
    "    except ZeroDivisionError:\n",
    "        recall = 0\n",
    "    try:\n",
    "        f1_score = 2 * (precision * recall) / (precision + recall)\n",
    "    except ZeroDivisionError:\n",
    "        f1_score = 0\n",
    "    # Write metric output to a new CSV file\n",
    "    metrics_df = pd.DataFrame(\n",
    "        {\n",
    "            \"accuracy\":     [accuracy],\n",
    "            \"precision\":    [precision],\n",
    "            \"recall\":       [recall],\n",
    "            \"f1_score\":     [f1_score],\n",
    "        }\n",
    "    )\n",
    "    return metrics_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load training data\n",
    "df_train = pd.read_csv(\"training_data/PreFer_train_data.csv\", low_memory=False)\n",
    "df_train_outcome = pd.read_csv(\"training_data/PreFer_train_outcome.csv\")\n",
    "\n",
    "# Clean training data using clean_df from submission.py\n",
    "df_train_cleaned = clean_df(df_train)\n",
    "\n",
    "# Train model and save\n",
    "train_save_model(df_train_cleaned, df_train_outcome)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "phi543-NLP-gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
